{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert \"Hey Nap\" ONNX to TFLite\n",
    "\n",
    "This notebook converts your ONNX model to TFLite format for ESP32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install compatible versions (fixes the mapping import error)\n",
    "!pip install -q \"onnx==1.15.0\" \"onnx-tf==1.11.0\" tensorflow\n",
    "print(\"‚úÖ Dependencies installed with compatible versions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload and rename file\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "print(\"üì§ Upload your ONNX file...\")\n",
    "uploaded = files.upload()\n",
    "onnx_file = list(uploaded.keys())[0]\n",
    "\n",
    "# Rename to remove spaces/special chars\n",
    "clean_name = \"hey_nap.onnx\"\n",
    "if onnx_file != clean_name:\n",
    "    os.rename(onnx_file, clean_name)\n",
    "    onnx_file = clean_name\n",
    "    print(f\"‚úÖ Renamed to: {clean_name}\")\n",
    "\n",
    "print(f\"‚úÖ File ready: {onnx_file}\")\n",
    "print(f\"   Size: {os.path.getsize(onnx_file) / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to TFLite using onnx-tf\n",
    "import onnx\n",
    "import tensorflow as tf\n",
    "from onnx_tf.backend import prepare\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "tflite_file = \"hey_nap.tflite\"\n",
    "\n",
    "print(f\"üîÑ Converting {onnx_file} to TFLite...\")\n",
    "print(\"\\nStep 1: Loading ONNX model...\")\n",
    "onnx_model = onnx.load(onnx_file)\n",
    "print(\"   ‚úÖ ONNX model loaded\")\n",
    "\n",
    "print(\"\\nStep 2: Converting to TensorFlow...\")\n",
    "tf_rep = prepare(onnx_model)\n",
    "print(\"   ‚úÖ TensorFlow representation created\")\n",
    "\n",
    "print(\"\\nStep 3: Exporting to SavedModel...\")\n",
    "with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "    tf_model_path = os.path.join(tmp_dir, \"saved_model\")\n",
    "    tf_rep.export_graph(tf_model_path)\n",
    "    print(\"   ‚úÖ SavedModel exported\")\n",
    "    \n",
    "    print(\"\\nStep 4: Converting to TFLite...\")\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(tf_model_path)\n",
    "    tflite_model = converter.convert()\n",
    "    \n",
    "    print(\"\\nStep 5: Saving TFLite file...\")\n",
    "    with open(tflite_file, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "\n",
    "print(f\"\\n‚úÖ Conversion successful!\")\n",
    "print(f\"   File: {tflite_file}\")\n",
    "print(f\"   Size: {os.path.getsize(tflite_file) / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download TFLite file\n",
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "tflite_file = \"hey_nap.tflite\"\n",
    "\n",
    "if os.path.exists(tflite_file):\n",
    "    print(f\"üì• Downloading {tflite_file}...\")\n",
    "    files.download(tflite_file)\n",
    "    print(f\"\\n‚úÖ Download complete!\")\n",
    "    print(f\"\\nüéâ Your TFLite model is ready for ESP32!\")\n",
    "    print(f\"\\nüìù Next steps:\")\n",
    "    print(f\"   1. Save to your project\")\n",
    "    print(f\"   2. Test: python3 test_hey_nap_local.py --model {tflite_file}\")\n",
    "    print(f\"   3. Deploy: cp {tflite_file} components/openwakeword/models/\")\n",
    "else:\n",
    "    print(f\"‚ùå File not found: {tflite_file}\")\n",
    "    print(\"\\nAvailable files:\")\n",
    "    !ls -la"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
